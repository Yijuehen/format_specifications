from zhipuai import ZhipuAI
from django.conf import settings
import logging
import time
from functools import wraps
import requests
from zhipuai.core import _errors
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Callable

# é…ç½®ç‹¬ç«‹æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

def cache_text_result(expire_seconds=30):
    """
    è£…é¥°å™¨ï¼šç¼“å­˜æ–‡æœ¬å¤„ç†ç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨ AI æ¥å£ï¼ˆæå‡æ€§èƒ½ï¼Œå‡å°‘è¶…æ—¶æ¦‚ç‡ï¼‰
    :param expire_seconds: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 30 ç§’
    """
    cache = {}  # key: æ–‡æœ¬ç‰¹å¾å€¼ï¼Œvalue: (å¤„ç†ç»“æœ, ç¼“å­˜æ—¶é—´æˆ³)

    def decorator(func):
        @wraps(func)
        def wrapper(self, raw_text, *args, **kwargs):
            # ç”Ÿæˆæ–‡æœ¬ç‰¹å¾å€¼ï¼ˆé¿å…é•¿æ–‡æœ¬ä½œä¸º keyï¼ŒèŠ‚çœå†…å­˜ï¼‰
            raw_text_strip = raw_text.strip() if raw_text else ""
            text_feature = f"{len(raw_text_strip)}_{raw_text_strip[:100]}"  # é•¿åº¦+å‰100å­—ç¬¦

            # æ£€æŸ¥ç¼“å­˜ï¼šæœªè¿‡æœŸåˆ™ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ
            current_time = time.time()
            if text_feature in cache:
                cached_result, cached_time = cache[text_feature]
                if current_time - cached_time < expire_seconds:
                    logger.info(f"å‘½ä¸­æ–‡æœ¬ç¼“å­˜ï¼Œç›´æ¥è¿”å›ç»“æœï¼ˆæ— éœ€é‡å¤è°ƒç”¨ AIï¼‰")
                    return cached_result

            # æœªå‘½ä¸­ç¼“å­˜ï¼šæ‰§è¡ŒåŸæ–¹æ³•
            result = func(self, raw_text, *args, **kwargs)

            # ç¼“å­˜ç»“æœ
            cache[text_feature] = (result, current_time)

            # æ¸…ç†è¿‡æœŸç¼“å­˜ï¼ˆé¿å…å†…å­˜æ³„éœ²ï¼‰
            for feature in list(cache.keys()):
                if current_time - cache[feature][1] > expire_seconds:
                    del cache[feature]

            return result
        return wrapper
    return decorator


def retry_on_connection_error(max_retries=3, backoff_factor=2, fallback_return=""):
    """
    è£…é¥°å™¨ï¼šåœ¨è¿æ¥é”™è¯¯æ—¶é‡è¯• AI è°ƒç”¨ï¼ˆæŒ‡æ•°é€€é¿ç­–ç•¥ï¼‰

    :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰
    :param backoff_factor: é€€é¿å› å­ï¼ˆé»˜è®¤ 2ï¼Œå³æ¯æ¬¡é‡è¯•ç­‰å¾…æ—¶é—´ç¿»å€ï¼‰
    :param fallback_return: å¤±è´¥æ—¶çš„è¿”å›å€¼ï¼ˆé»˜è®¤ç©ºå­—ç¬¦ä¸²ï¼Œå¯è®¾ç½®ä¸º 'raw_text' è¿”å›åŸå§‹æ–‡æœ¬ï¼‰
    """
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            last_exception = None
            wait_time = 1  # åˆå§‹ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

            for attempt in range(max_retries):
                try:
                    return func(self, *args, **kwargs)
                except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        logger.warning(f"AI æ¥å£è¿æ¥å¤±è´¥ï¼ˆç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼‰ï¼Œ{wait_time} ç§’åé‡è¯•...")
                        self.log_callback(f"âš ï¸ è¿æ¥å¤±è´¥ï¼Œ{wait_time} ç§’åé‡è¯• ({attempt + 1}/{max_retries})...")
                        time.sleep(wait_time)
                        wait_time *= backoff_factor  # æŒ‡æ•°é€€é¿
                    else:
                        logger.error(f"AI æ¥å£è¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})")
                        self.log_callback(f"âŒ è¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")

                except Exception as e:
                    # å…¶ä»–å¼‚å¸¸ç›´æ¥æŠ›å‡ºï¼Œä¸é‡è¯•
                    raise e

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åï¼Œè¿”å› fallback å€¼
            if fallback_return == "raw_text" and args:
                # å¯¹äº process_text æ–¹æ³•ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                raw_text = args[0] if args else ""
                raw_text_strip = raw_text.strip() if raw_text else ""
                logger.error(f"AI å¤„ç†å¤±è´¥ï¼ˆè¿æ¥é”™è¯¯ï¼‰ï¼Œè¿”å›åŸå§‹æ–‡æœ¬: {str(last_exception)}")
                self.log_callback(f"âš ï¸ AI è¿æ¥å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬")
                return raw_text_strip
            else:
                # å¯¹äºå…¶ä»–æ–¹æ³•ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
                logger.error(f"AI å¤„ç†å¤±è´¥ï¼ˆè¿æ¥é”™è¯¯ï¼‰ï¼Œè¿”å›ç©ºå€¼: {str(last_exception)}")
                self.log_callback(f"âš ï¸ AI è¿æ¥å¤±è´¥ï¼Œè·³è¿‡æ­¤éƒ¨åˆ†")
                return ""

        return wrapper
    return decorator

class AITextProcessor:
    def __init__(self, tone='no_preference', log_callback=None):
        """
        åˆå§‹åŒ–æ™ºè°± AI å®¢æˆ·ç«¯ï¼Œé…ç½®è¶…æ—¶å‚æ•°

        å‚æ•°:
        - tone: æ–‡æ¡£è¯­è°ƒ (no_preference, direct, rigorous, empathetic, inspirational, humorous, cold_sharp)
        - log_callback: æ—¥å¿—å›è°ƒå‡½æ•° (å¯é€‰)
        """
        # ä» Django é…ç½®ä¸­è¯»å– API å¯†é’¥å’Œæ¨¡å‹ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
        self.api_key = settings.ZHIPU_API_KEY
        self.model = settings.ZHIPU_MODEL or "glm-4"
        self.client = ZhipuAI(api_key=self.api_key)

        # è¯­è°ƒè®¾ç½®
        self.tone = tone

        # æ—¥å¿—å›è°ƒå‡½æ•°
        self.log_callback = log_callback or (lambda msg: logger.info(msg))

        # æ€§èƒ½ä¼˜åŒ–ï¼šè®¾ç½®æ¥å£è¶…æ—¶æ—¶é—´ï¼ˆé¿å…æ— é™ç­‰å¾…ï¼Œé»˜è®¤ 15 ç§’ï¼‰
        self.request_timeout = 15
        # æ€§èƒ½ä¼˜åŒ–ï¼šé™åˆ¶å•æ¬¡å¤„ç†æ–‡æœ¬æœ€å¤§é•¿åº¦ï¼ˆé¿å…è¶…å¤§æ–‡æœ¬è¶…æ—¶ï¼Œå¯æ ¹æ®æ¨¡å‹è°ƒæ•´ï¼‰
        self.max_text_length = 1000

        logger.info("AI æ–‡æœ¬å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆè¶…æ—¶æ—¶é—´ï¼š%d ç§’ï¼Œæœ€å¤§æ–‡æœ¬é•¿åº¦ï¼š%d å­—ç¬¦ï¼Œè¯­è°ƒï¼š%sï¼‰",
                    self.request_timeout, self.max_text_length, tone)

    @cache_text_result(expire_seconds=30)
    @retry_on_connection_error(max_retries=3, backoff_factor=2, fallback_return="raw_text")
    def process_text(self, raw_text):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šè°ƒç”¨æ™ºè°± AI å®Œæˆæ–‡æœ¬æ¶¦è‰²ï¼Œè§£å†³è¿”å›ç©º + é¿å…è¶…æ—¶

        :param raw_text: åŸå§‹å¤§æ®µæ–‡å­—
        :return: AI å¤„ç†åçš„ç»“æ„åŒ–æ–‡å­—ï¼ˆæ°¸ä¸è¿”å›ç©ºï¼Œå¼‚å¸¸æ—¶è¿”å›åŸå§‹æ–‡æœ¬ï¼‰
        """
        # ç¬¬ä¸€æ­¥ï¼šå‰ç½®æ ¡éªŒï¼ˆé¿å…æ— æ„ä¹‰è°ƒç”¨ï¼Œæå‡æ€§èƒ½ï¼‰
        if not raw_text or not raw_text.strip():
            logger.error("åŸå§‹æ–‡æœ¬ä¸ºç©ºï¼Œæ— éœ€å¤„ç†")
            return ""  # å…œåº•è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œä¸è¿”å› None

        raw_text_strip = raw_text.strip()

        # ç¬¬äºŒæ­¥ï¼šè¶…é•¿æ–‡æœ¬é™åˆ¶ï¼ˆé¿å… AI å¤„ç†è€—æ—¶è¿‡ä¹…å¯¼è‡´è¶…æ—¶ï¼‰
        if len(raw_text_strip) > self.max_text_length:
            logger.warning(f"æ–‡æœ¬è¿‡é•¿ï¼ˆ{len(raw_text_strip)} å­—ç¬¦ï¼‰ï¼Œè¶…è¿‡å•æ¬¡å¤„ç†ä¸Šé™ï¼ˆ{self.max_text_length} å­—ç¬¦ï¼‰ï¼Œè¿”å›åŸå§‹æ–‡æœ¬é¿å…è¶…æ—¶")
            return raw_text_strip

        # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºè¯­è°ƒæç¤ºè¯
        tone_instructions = self._get_tone_instruction()

        # ç¬¬å››æ­¥ï¼šæ„å»ºç®€æ´ Promptï¼ˆå‡å°‘ AI æ€è€ƒæ—¶é—´ï¼Œæå‡å“åº”é€Ÿåº¦ï¼‰
        prompt = f"""{tone_instructions}
è¯·æ¶¦è‰²ä»¥ä¸‹æ–‡å­—ï¼Œä½¿å…¶æ›´é€šé¡ºæ­£å¼ï¼Œå¹¶é€‚å½“åˆ†æ®µå’Œåˆ†ç‚¹ï¼Œç›´æ¥è¿”å›å¤„ç†åçš„æ–‡å­—ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚
æ–‡å­—ï¼š{raw_text_strip}"""

        try:
            # ç¬¬äº”æ­¥ï¼šè°ƒç”¨æ™ºè°± AI æ¥å£ï¼ˆè®¾ç½®è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…ï¼‰
            self.log_callback("æ­£åœ¨è°ƒç”¨ AI å¤„ç†æ–‡æœ¬...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ–‡å­—å¤„ç†åŠ©æ‰‹ï¼Œæ“…é•¿ç»“æ„åŒ–æ–‡æœ¬ä¼˜åŒ–ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # æ¸©åº¦è¶Šä½ï¼Œç»“æœè¶Šç¨³å®šï¼Œå¤„ç†é€Ÿåº¦è¶Šå¿«
                max_tokens=2000,
                timeout=self.request_timeout  # æ ¸å¿ƒï¼šè®¾ç½®æ¥å£è¶…æ—¶æ—¶é—´
            )

            # ç¬¬å…­æ­¥ï¼šæå–ç»“æœ + å¤šå±‚å…œåº•æ ¡éªŒï¼ˆé¿å…è¿”å›ç©ºï¼‰
            raw_content = getattr(response.choices[0].message, "content", "") or ""
            processed_text = raw_content.strip()

            # æ ¡éªŒå¤„ç†ç»“æœï¼šä¸ºç©ºåˆ™æŠ›å‡ºå¼‚å¸¸ï¼Œè¿›å…¥å…œåº•é€»è¾‘
            if not processed_text:
                logger.error("AI è¿”å›ç©ºå†…å®¹ï¼ˆæ¥å£å“åº”æ­£å¸¸ï¼Œä½†å†…å®¹ä¸ºç©ºï¼‰")
                raise ValueError("AI è¿”å›ç©ºå†…å®¹ï¼Œå¤„ç†å¤±è´¥")

            logger.info(f"AI æ–‡æœ¬å¤„ç†å®Œæˆï¼Œè¿”å›æ–‡æœ¬é•¿åº¦: {len(processed_text)} å­—ç¬¦")
            self.log_callback(f"âœ… æ–‡æœ¬å¤„ç†å®Œæˆ ({len(processed_text)} å­—ç¬¦)")
            return processed_text

        # é’ˆå¯¹æ€§æ•è·ï¼šè¶…æ—¶å¼‚å¸¸ï¼ˆæœ€æ˜“å¯¼è‡´ç©ºå†…å®¹çš„æ€§èƒ½é—®é¢˜ï¼‰
        except requests.exceptions.Timeout:
            error_msg = f"AI æ¥å£è¯·æ±‚è¶…æ—¶ï¼ˆè¶…è¿‡ {self.request_timeout} ç§’ï¼‰ï¼Œè¿”å›åŸå§‹æ–‡æœ¬"
            logger.error(error_msg)
            self.log_callback(f"âš ï¸ {error_msg}")
            return raw_text_strip

        # é’ˆå¯¹æ€§æ•è·ï¼šç½‘ç»œè¿æ¥å¼‚å¸¸
        except requests.exceptions.ConnectionError:
            error_msg = "ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œæ— æ³•è°ƒç”¨ AI æ¥å£ï¼Œè¿”å›åŸå§‹æ–‡æœ¬"
            logger.error(error_msg)
            self.log_callback(f"âš ï¸ {error_msg}")
            return raw_text_strip

        # é’ˆå¯¹æ€§æ•è·ï¼šä¸šåŠ¡é€»è¾‘å¼‚å¸¸ï¼ˆå¦‚è¿”å›æ ¼å¼é”™è¯¯ã€ç©ºå€¼ï¼‰
        except (ValueError, AttributeError) as e:
            error_msg = f"AI æ–‡æœ¬å¤„ç†ä¸šåŠ¡å¼‚å¸¸: {str(e)}ï¼Œè¿”å›åŸå§‹æ–‡æœ¬"
            logger.error(error_msg)
            self.log_callback(f"âš ï¸ {error_msg}")
            return raw_text_strip

    def _get_tone_instruction(self):
        """
        æ ¹æ®è¯­è°ƒè®¾ç½®è¿”å›ç›¸åº”çš„æç¤ºè¯

        :return: è¯­è°ƒæç¤ºæ–‡å­—ç¬¦ä¸²
        """
        tone_map = {
            'no_preference': "è¯·ä¿æŒå®¢è§‚ã€ä¸­ç«‹çš„è¯­è°ƒã€‚",
            'direct': "è¯·ä½¿ç”¨ç®€æ´ã€ç›´æ¥çš„è¯­è°ƒï¼Œé¿å…å†—ä½™è¡¨è¾¾ï¼Œç›´å¥”ä¸»é¢˜ã€‚",
            'rigorous': "è¯·ä½¿ç”¨ä¸¥è°¨ã€ä¸“ä¸šçš„è¯­è°ƒï¼Œä½¿ç”¨å‡†ç¡®çš„æœ¯è¯­å’Œå®Œæ•´çš„è¡¨è¾¾ã€‚",
            'empathetic': "è¯·ä½¿ç”¨äº²åˆ‡ã€æ¸©æš–çš„è¯­è°ƒï¼Œä½“ç°å…³æ€€å’Œç†è§£ã€‚",
            'inspirational': "è¯·ä½¿ç”¨é¼“èˆäººå¿ƒçš„è¯­è°ƒï¼Œä¼ é€’ç§¯æå‘ä¸Šçš„èƒ½é‡ã€‚",
            'humorous': "è¯·ä½¿ç”¨è½»æ¾æœ‰è¶£çš„è¯­è°ƒï¼Œå¯ä»¥é€‚å½“åŠ å…¥å¹½é»˜å…ƒç´ ã€‚",
            'cold_sharp': "è¯·ä½¿ç”¨æƒå¨ã€æœæ–­çš„è¯­è°ƒï¼Œç›´æ¥é™ˆè¿°ï¼Œä¸å¸¦æƒ…æ„Ÿè‰²å½©ã€‚"
        }

        return tone_map.get(self.tone, "è¯·ä¿æŒå®¢è§‚ã€ä¸­ç«‹çš„è¯­è°ƒã€‚")

    def generate_from_template(
        self,
        template,
        user_outline="",
        source_document_text="",
        tone=None
    ):
        """
        æ ¹æ®æ¨¡æ¿ç”Ÿæˆå†…å®¹ï¼ˆé¡ºåºå¤„ç†æ¨¡å¼ï¼‰

        å‚æ•°:
        - template: æ¨¡æ¿å¯¹è±¡
        - user_outline: ç”¨æˆ·å¤§çº²
        - source_document_text: æºæ–‡æ¡£æ–‡æœ¬
        - tone: è¯­è°ƒ

        è¿”å›:
        - dict: {section_id: generated_content}
        """
        generated_content = {}

        # é€’å½’å¤„ç†æ‰€æœ‰ç« èŠ‚
        def process_sections(sections):
            for section in sections:
                # ä¸ºå½“å‰ç« èŠ‚ç”Ÿæˆå†…å®¹
                section_content = self._generate_section_content(
                    section,
                    user_outline,
                    source_document_text
                )
                if section_content:
                    generated_content[section.id] = section_content
                    self.log_callback(f"âœ“ å·²ç”Ÿæˆ: {section.title}")

                # é€’å½’å¤„ç†å­ç« èŠ‚
                if section.subsections:
                    process_sections(section.subsections)

        process_sections(template.sections)
        return generated_content

    def generate_from_template_batch(
        self,
        template,
        user_outline="",
        source_document_text="",
        tone=None
    ):
        """
        æ ¹æ®æ¨¡æ¿ç”Ÿæˆå†…å®¹ï¼ˆæ‰¹é‡å¤„ç†æ¨¡å¼ï¼‰

        å‚æ•°:
        - template: æ¨¡æ¿å¯¹è±¡
        - user_outline: ç”¨æˆ·å¤§çº²
        - source_document_text: æºæ–‡æ¡£æ–‡æœ¬
        - tone: è¯­è°ƒ

        è¿”å›:
        - dict: {section_id: generated_content}
        """
        # æ‰¹é‡æ¨¡å¼ï¼šä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ç« èŠ‚
        generated_content = {}

        # æ„å»ºæ‰€æœ‰ç« èŠ‚çš„æç¤º
        sections_info = []
        def collect_sections(sections):
            for section in sections:
                sections_info.append(f"- {section.title}")
                if section.subsections:
                    collect_sections(section.subsections)

        collect_sections(template.sections)

        # æ„å»ºæ‰¹é‡æç¤ºè¯
        tone_instruction = self._get_tone_instruction()
        sections_list = "\n".join(sections_info)

        prompt = f"""{tone_instruction}

è¯·æ ¹æ®ä»¥ä¸‹æ¨¡æ¿ç»“æ„ï¼Œä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå†…å®¹ã€‚

æ¨¡æ¿ç« èŠ‚ï¼š
{sections_list}

ç”¨æˆ·å¤§çº²ï¼š{user_outline}

æºæ–‡æ¡£å†…å®¹ï¼š{source_document_text[:2000]}

è¯·ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¯¦ç»†å†…å®¹ï¼ŒæŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼š
ç« èŠ‚1æ ‡é¢˜
[ç« èŠ‚1å†…å®¹]

ç« èŠ‚2æ ‡é¢˜
[ç« èŠ‚2å†…å®¹]

...

è¯·ç¡®ä¿å†…å®¹ä¸“ä¸šã€å®Œæ•´ï¼Œæ¯ä¸ªç« èŠ‚è‡³å°‘200å­—ã€‚"""

        try:
            self.log_callback("æ­£åœ¨æ‰¹é‡ç”Ÿæˆæ‰€æœ‰ç« èŠ‚å†…å®¹...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®æ¨¡æ¿ç»“æ„ç”Ÿæˆé«˜è´¨é‡çš„æ–‡æ¡£å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=4000,
                timeout=self.request_timeout
            )

            content = response.choices[0].message.content.strip()

            # è§£æè¿”å›çš„å†…å®¹ï¼Œåˆ†é…åˆ°å„ä¸ªç« èŠ‚
            current_section = None
            current_content = []

            def assign_sections(sections):
                for section in sections:
                    if current_section and current_content:
                        generated_content[current_section.id] = "\n".join(current_content)
                        self.log_callback(f"âœ“ å·²ç”Ÿæˆ: {section.title}")
                        current_content.clear()

                    current_section = section

                    if section.subsections:
                        assign_sections(section.subsections)

                # æœ€åä¸€ä¸ªç« èŠ‚
                if current_section and current_content:
                    generated_content[current_section.id] = "\n".join(current_content)

            assign_sections(template.sections)

            return generated_content

        except Exception as e:
            logger.error(f"æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            self.log_callback(f"âš ï¸ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
            # é™çº§åˆ°é¡ºåºå¤„ç†æ¨¡å¼
            self.log_callback("é™çº§åˆ°é¡ºåºå¤„ç†æ¨¡å¼...")
            return self.generate_from_template(template, user_outline, source_document_text, tone)

    def generate_from_template_parallel(
        self,
        template,
        user_outline="",
        source_document_text="",
        tone=None,
        max_workers=5
    ):
        """
        æ ¹æ®æ¨¡æ¿ç”Ÿæˆå†…å®¹ï¼ˆå¹¶è¡Œå¤„ç†æ¨¡å¼ï¼‰

        ä½¿ç”¨å¤šçº¿ç¨‹å¹¶å‘å¤„ç†å¤šä¸ªç« èŠ‚ï¼Œæ˜¾è‘—æå‡å¤„ç†é€Ÿåº¦

        å‚æ•°:
        - template: æ¨¡æ¿å¯¹è±¡
        - user_outline: ç”¨æˆ·å¤§çº²
        - source_document_text: æºæ–‡æ¡£æ–‡æœ¬
        - tone: è¯­è°ƒ
        - max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤5ï¼Œæ ¹æ®APIé™æµå¯è°ƒæ•´ï¼‰

        è¿”å›:
        - dict: {section_id: generated_content}
        """
        generated_content = {}

        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„ç« èŠ‚ï¼ˆåŒ…æ‹¬å­ç« èŠ‚ï¼‰
        all_sections = []

        def collect_sections(sections, level=1):
            for section in sections:
                all_sections.append(section)
                if section.subsections:
                    collect_sections(section.subsections, level + 1)

        collect_sections(template.sections)

        self.log_callback(f"ğŸš€ å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼šåŒæ—¶å¤„ç† {len(all_sections)} ä¸ªç« èŠ‚ï¼ˆ{max_workers} çº¿ç¨‹å¹¶å‘ï¼‰")

        # å®šä¹‰å¤„ç†å•ä¸ªç« èŠ‚çš„å‡½æ•°
        def process_single_section(section):
            """å¤„ç†å•ä¸ªç« èŠ‚å¹¶è¿”å›ç»“æœ"""
            try:
                section_content = self._generate_section_content(
                    section,
                    user_outline,
                    source_document_text
                )
                if section_content:
                    return (section.id, section_content, section.title, None)
                else:
                    return (section.id, "", section.title, "ç”Ÿæˆå†…å®¹ä¸ºç©º")
            except Exception as e:
                logger.error(f"å¤„ç†ç« èŠ‚ '{section.title}' æ—¶å‡ºé”™: {str(e)}")
                return (section.id, "", section.title, str(e))

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ‰€æœ‰ç« èŠ‚
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_section = {
                executor.submit(process_single_section, section): section
                for section in all_sections
            }

            # æ”¶é›†å®Œæˆçš„ä»»åŠ¡
            completed = 0
            total = len(all_sections)

            for future in as_completed(future_to_section):
                section = future_to_section[future]
                try:
                    section_id, content, title, error = future.result()

                    if error:
                        self.log_callback(f"âš ï¸ å¤±è´¥: {title} - {error}")
                    elif content:
                        generated_content[section_id] = content
                        completed += 1
                        self.log_callback(f"âœ“ å·²ç”Ÿæˆ [{completed}/{total}]: {title}")

                except Exception as e:
                    logger.error(f"å¤„ç†ç« èŠ‚æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                    self.log_callback(f"âš ï¸ å¼‚å¸¸: {section.title}")

        self.log_callback(f"âœ… å¹¶è¡Œå¤„ç†å®Œæˆï¼šæˆåŠŸç”Ÿæˆ {len(generated_content)}/{total} ä¸ªç« èŠ‚")
        return generated_content

    @retry_on_connection_error(max_retries=3, backoff_factor=2)
    def extract_section_for_structure(self, source_text, section_title):
        """
        ä¸ºè‡ªå®šä¹‰ç»“æ„æå–ç›¸å…³å†…å®¹

        å‚æ•°:
        - source_text: æºæ–‡æœ¬
        - section_title: ç« èŠ‚æ ‡é¢˜

        è¿”å›:
        - str: æå–çš„ç›¸å…³å†…å®¹
        """
        # ä½¿ç”¨AIæå–ä¸ç« èŠ‚ç›¸å…³çš„å†…å®¹
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–ä¸"{section_title}"ç›¸å…³çš„æ‰€æœ‰å†…å®¹ã€‚

æºæ–‡æœ¬ï¼š
{source_text[:3000]}

è¯·åªè¿”å›ç›¸å…³çš„å†…å®¹ç‰‡æ®µï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ€»ç»“ã€‚"""

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å†…å®¹æå–åŠ©æ‰‹ï¼Œæ“…é•¿ä»æ–‡æ¡£ä¸­æå–ç‰¹å®šä¸»é¢˜çš„ç›¸å…³å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=2000,
            timeout=self.request_timeout
        )

        extracted = response.choices[0].message.content.strip()
        logger.info(f"ä¸ºç« èŠ‚ '{section_title}' æå–äº† {len(extracted)} å­—ç¬¦")
        return extracted

    def extract_sections_for_structure_parallel(
        self,
        source_text: str,
        section_titles: List[str],
        max_workers: int = 5
    ) -> Dict[str, str]:
        """
        å¹¶è¡Œæå–å¤šä¸ªç« èŠ‚çš„ç›¸å…³å†…å®¹

        å‚æ•°:
        - source_text: æºæ–‡æœ¬
        - section_titles: ç« èŠ‚æ ‡é¢˜åˆ—è¡¨
        - max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°

        è¿”å›:
        - dict: {section_title: extracted_content}
        """
        self.log_callback(f"ğŸš€ å¹¶è¡Œæå–ï¼šåŒæ—¶å¤„ç† {len(section_titles)} ä¸ªç« èŠ‚")

        def extract_single_section(section_title: str) -> tuple:
            """æå–å•ä¸ªç« èŠ‚çš„å†…å®¹"""
            try:
                content = self.extract_section_for_structure(source_text, section_title)
                return (section_title, content, None)
            except Exception as e:
                logger.error(f"æå–ç« èŠ‚ '{section_title}' æ—¶å‡ºé”™: {str(e)}")
                return (section_title, "", str(e))

        results = {}
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(extract_single_section, title): title
                for title in section_titles
            }

            completed = 0
            for future in as_completed(futures):
                section_title, content, error = future.result()
                if error:
                    self.log_callback(f"âš ï¸ æå–å¤±è´¥: {section_title}")
                else:
                    results[section_title] = content
                    completed += 1
                    self.log_callback(f"âœ“ å·²æå– [{completed}/{len(section_titles)}]: {section_title}")

        self.log_callback(f"âœ… å¹¶è¡Œæå–å®Œæˆï¼šæˆåŠŸæå– {len(results)}/{len(section_titles)} ä¸ªç« èŠ‚")
        return results

    def polish_sections_parallel(
        self,
        sections_data: Dict[str, str],
        max_workers: int = 5
    ) -> Dict[str, str]:
        """
        å¹¶è¡Œæ¶¦è‰²å¤šä¸ªç« èŠ‚çš„å†…å®¹

        å‚æ•°:
        - sections_data: {section_title: raw_content} å­—å…¸
        - max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°

        è¿”å›:
        - dict: {section_title: polished_content}
        """
        self.log_callback(f"ğŸš€ å¹¶è¡Œæ¶¦è‰²ï¼šåŒæ—¶å¤„ç† {len(sections_data)} ä¸ªç« èŠ‚")

        def polish_single_section(item: tuple) -> tuple:
            """æ¶¦è‰²å•ä¸ªç« èŠ‚"""
            section_title, raw_content = item
            try:
                if not raw_content or len(raw_content.strip()) < 10:
                    return (section_title, "", "å†…å®¹è¿‡çŸ­")
                polished = self.process_text(raw_content)
                return (section_title, polished, None)
            except Exception as e:
                logger.error(f"æ¶¦è‰²ç« èŠ‚ '{section_title}' æ—¶å‡ºé”™: {str(e)}")
                return (section_title, "", str(e))

        results = {}
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(polish_single_section, item): item[0]
                for item in sections_data.items()
            }

            completed = 0
            for future in as_completed(futures):
                section_title, polished, error = future.result()
                if error:
                    results[section_title] = ""
                    self.log_callback(f"âš ï¸ æ¶¦è‰²å¤±è´¥: {section_title}")
                else:
                    results[section_title] = polished
                    completed += 1
                    self.log_callback(f"âœ“ å·²æ¶¦è‰² [{completed}/{len(sections_data)}]: {section_title}")

        self.log_callback(f"âœ… å¹¶è¡Œæ¶¦è‰²å®Œæˆï¼šæˆåŠŸæ¶¦è‰² {len([r for r in results.values() if r])}/{len(sections_data)} ä¸ªç« èŠ‚")
        return results

    def segment_text(self, text, mode="paragraph", include_metadata=False):
        """
        åˆ†å‰²æ–‡æœ¬

        å‚æ•°:
        - text: è¦åˆ†å‰²çš„æ–‡æœ¬
        - mode: åˆ†å‰²æ¨¡å¼ (paragraph/sentence/semantic)
        - include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®

        è¿”å›:
        - list: åˆ†å‰²åçš„æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨ï¼ˆæˆ–å­—å…¸åˆ—è¡¨ï¼Œå¦‚æœ include_metadata=Trueï¼‰
        """
        if mode == "paragraph":
            segments = text.split("\n\n")
        elif mode == "sentence":
            import re
            segments = re.split(r'[ã€‚ï¼ï¼Ÿ\.!?]', text)
            segments = [s.strip() for s in segments if s.strip()]
        elif mode == "semantic":
            # è¯­ä¹‰åˆ†å‰²ï¼šæŒ‰æ®µè½åˆ†å‰²ï¼ˆç®€å•å®ç°ï¼‰
            segments = text.split("\n\n")
        else:
            segments = [text]

        if include_metadata:
            return [
                {
                    "type": mode,
                    "text": segment,
                    "position": i
                }
                for i, segment in enumerate(segments)
            ]
        else:
            return segments

    @retry_on_connection_error(max_retries=3, backoff_factor=2)
    def _generate_section_content(self, section, user_outline, source_text):
        """
        ä¸ºå•ä¸ªç« èŠ‚ç”Ÿæˆå†…å®¹

        å‚æ•°:
        - section: ç« èŠ‚å¯¹è±¡
        - user_outline: ç”¨æˆ·å¤§çº²
        - source_text: æºæ–‡æœ¬

        è¿”å›:
        - str: ç”Ÿæˆçš„å†…å®¹
        """
        tone_instruction = self._get_tone_instruction()

        prompt = f"""{tone_instruction}

è¯·ä¸ºä»¥ä¸‹ç« èŠ‚ç”Ÿæˆè¯¦ç»†å†…å®¹ï¼š

ç« èŠ‚æ ‡é¢˜ï¼š{section.title}

ç« èŠ‚æè¿°ï¼š{section.title}

ç”¨æˆ·æä¾›çš„è¦ç‚¹ï¼š{user_outline}

æºæ–‡æ¡£å‚è€ƒå†…å®¹ï¼š{source_text[:1500] if source_text else "æ— "}

è¯·ç”Ÿæˆè¯¥ç« èŠ‚çš„è¯¦ç»†å†…å®¹ï¼ˆè‡³å°‘300å­—ï¼‰ï¼Œè¦æ±‚ï¼š
1. å†…å®¹ä¸“ä¸šã€å®Œæ•´
2. æ¡ç†æ¸…æ™°ã€é€»è¾‘ä¸¥å¯†
3. ç¬¦åˆç« èŠ‚ä¸»é¢˜
4. å¯ä»¥é€‚å½“ä½¿ç”¨åˆ†ç‚¹è¯´æ˜

ç›´æ¥è¿”å›ç”Ÿæˆçš„å†…å®¹ï¼Œä¸è¦åŒ…å«ç« èŠ‚æ ‡é¢˜ã€‚"""

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å†…å®¹ç”ŸæˆåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®æ¨¡æ¿å’Œæºæ–‡æ¡£ç”Ÿæˆé«˜è´¨é‡çš„ç« èŠ‚å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000,
            timeout=self.request_timeout
        )

        content = response.choices[0].message.content.strip()

        # æ£€æŸ¥æ˜¯å¦å¤ªçŸ­
        if len(content) < 50:
            logger.warning(f"ç« èŠ‚ '{section.title}' ç”Ÿæˆçš„å†…å®¹è¿‡çŸ­ ({len(content)} å­—ç¬¦)")
            return ""

        return content