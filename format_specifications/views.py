from django.shortcuts import render
from django.http import FileResponse, HttpResponseBadRequest, HttpResponse, JsonResponse
from django.views.decorators.http import require_http_methods
from .utils import generate_output_path
from .utils.word_formatter import AIWordFormatter
from .utils.ai_word_utils import AITextProcessor
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import os
from datetime import datetime
from django.conf import settings
import logging
import tempfile
import re

# è·å–loggerå®ä¾‹
logger = logging.getLogger(__name__)

# Processing log helper
def add_processing_log(request, message):
    """Add a log entry to processing status session"""
    if 'processing' not in request.session:
        request.session['processing'] = {
            'status': 'processing',
            'logs': [],
            'current_step': 0,
            'total_steps': 0
        }

    log_entry = {
        'msg': message,
        'time': datetime.now().strftime('%H:%M:%S')
    }

    # Keep only last 50 log entries to prevent session bloat
    logs = request.session['processing']['logs']
    logs.append(log_entry)
    if len(logs) > 50:
        logs.pop(0)

    request.session['processing']['logs'] = logs
    request.session.modified = True  # Ensure session is saved
    logger.debug(f"Processing log: {message}")

# ä¸Šä¼ é¡µé¢ï¼ˆæ–°å¢ AI å¼€å…³é€‰é¡¹ï¼‰
def upload_word_page(request):
    logger.info("è®¿é—®ä¸Šä¼ é¡µé¢")

    # Get templates for template generation section
    from .services.template_manager import TemplateManager
    templates = TemplateManager.list_available_templates(
        request.user if request.user.is_authenticated else None
    )

    logger.info(f"åŠ è½½äº† {len(templates)} ä¸ªæ¨¡æ¿")
    for template_id, name, category, template_type in templates[:3]:
        logger.info(f"  - æ¨¡æ¿: {template_id} = {name} ({category})")

    return render(request, 'upload_word_ai.html', {
        'templates': templates
    })

# å¤„ç† AI è¾…åŠ©æ ¼å¼åŒ–
@require_http_methods(["POST"])
def ai_format_word(request):
    logger.info("å¼€å§‹å¤„ç†AIæ ¼å¼åŒ–è¯·æ±‚")

    # 1. Get optimization mode
    optimization_mode = request.POST.get('optimization_mode', 'simple')
    logger.info(f"Optimization mode: {optimization_mode}")

    # 2. Check file upload (always required)
    if 'word_file' not in request.FILES:
        error_msg = "è¯·ä¸Šä¼  Word æ–‡ä»¶"
        logger.warning(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    uploaded_file = request.FILES['word_file']
    if not uploaded_file.name.endswith(('.docx',)):
        error_msg = "ä»…æ”¯æŒ .docx æ ¼å¼ï¼ˆ.doc éœ€å…ˆè½¬æ¢ä¸º .docxï¼‰"
        logger.warning(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    # 3. Route based on mode
    if optimization_mode == 'simple':
        return handle_simple_optimization(request, uploaded_file)
    elif optimization_mode == 'template':
        return handle_template_optimization(request, uploaded_file)
    elif optimization_mode == 'custom':
        return handle_custom_optimization(request, uploaded_file)
    else:
        error_msg = f"æ— æ•ˆçš„ä¼˜åŒ–æ¨¡å¼: {optimization_mode}"
        logger.error(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})


def handle_simple_optimization(request, uploaded_file):
    """Handle simple optimization mode (existing functionality)"""
    logger.info("Processing simple optimization mode")

    # Check if AI is enabled
    use_ai_raw = request.POST.get('use_ai')
    use_ai = use_ai_raw == 'on'
    logger.info(f"AIåŠŸèƒ½å¯ç”¨çŠ¶æ€: {use_ai} (åŸå§‹å€¼: '{use_ai_raw}')")

    # Get tone parameter
    tone = request.POST.get('tone', 'no_preference')
    logger.info(f"é€‰æ‹©çš„è¯­è°ƒ: {tone}")

    # Get style template
    style_template = request.POST.get('style_template', 'default')

    # è°ƒè¯•ï¼šè®°å½•æ¥æ”¶åˆ°çš„åŸå§‹å­—å·å€¼
    raw_heading_size = request.POST.get('heading_size')
    raw_body_size = request.POST.get('body_size')
    logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°æ ‡é¢˜å­—å·: '{raw_heading_size}' (ç±»å‹: {type(raw_heading_size).__name__ if raw_heading_size else 'None'})")
    logger.info(f"ğŸ“¥ æ¥æ”¶åˆ°æ­£æ–‡å­—å·: '{raw_body_size}' (ç±»å‹: {type(raw_body_size).__name__ if raw_body_size else 'None'})")

    # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨è½¬æ¢æ•°å€¼ï¼Œç©ºå­—ç¬¦ä¸²è¿”å› None
    def safe_int(value):
        if value and value.strip():
            try:
                return int(value)
            except (ValueError, TypeError):
                return None
        return None

    def safe_float(value):
        if value and value.strip():
            try:
                return float(value)
            except (ValueError, TypeError):
                return None
        return None

    # å¤„ç†è‡ªå®šä¹‰å›¾ç‰‡å°ºå¯¸ï¼ˆæ”¯æŒè‹±å¯¸å’Œå˜ç±³ï¼‰
    image_width_value = request.POST.get('image_width')
    if image_width_value == 'custom':
        width_custom = safe_float(request.POST.get('image_width_custom'))
        width_unit = request.POST.get('image_width_unit', 'inch')
        if width_custom:
            # å¦‚æœæ˜¯å˜ç±³ï¼Œè½¬æ¢ä¸ºè‹±å¯¸ï¼ˆ1è‹±å¯¸ = 2.54å˜ç±³ï¼‰
            image_width = width_custom if width_unit == 'inch' else width_custom / 2.54
        else:
            image_width = None
    else:
        image_width = safe_float(image_width_value)

    image_height_value = request.POST.get('image_height')
    if image_height_value == 'custom':
        height_custom = safe_float(request.POST.get('image_height_custom'))
        height_unit = request.POST.get('image_height_unit', 'inch')
        if height_custom:
            # å¦‚æœæ˜¯å˜ç±³ï¼Œè½¬æ¢ä¸ºè‹±å¯¸ï¼ˆ1è‹±å¯¸ = 2.54å˜ç±³ï¼‰
            image_height = height_custom if height_unit == 'inch' else height_custom / 2.54
        else:
            image_height = None
    else:
        image_height = safe_float(image_height_value)

    custom_config = {
        'heading_font': request.POST.get('heading_font') or None,
        # å­—å·æ”¯æŒä¸­æ–‡ä»£ç ï¼ˆå¦‚ 'xiaosi'ï¼‰æˆ–æ•°å€¼ï¼Œä¸ä½¿ç”¨ safe_int è½¬æ¢
        'heading_size': request.POST.get('heading_size') or None,
        'body_font': request.POST.get('body_font') or None,
        # å­—å·æ”¯æŒä¸­æ–‡ä»£ç ï¼ˆå¦‚ 'xiaosi'ï¼‰æˆ–æ•°å€¼ï¼Œä¸ä½¿ç”¨ safe_int è½¬æ¢
        'body_size': request.POST.get('body_size') or None,
        'line_spacing': safe_float(request.POST.get('line_spacing')),
        'image_width': image_width,
        'image_height': image_height,
    }

    # åˆå¹¶æ¨¡æ¿å’Œè‡ªå®šä¹‰å€¼
    from format_specifications.utils.word_formatter import STYLE_TEMPLATES
    style_config = STYLE_TEMPLATES[style_template].copy()
    for key, value in custom_config.items():
        if value is not None:
            style_config[key] = value

    logger.info(f"æ ·å¼æ¨¡æ¿: {style_template}, åˆå¹¶åé…ç½®: {style_config}")

    # 3. ä¿å­˜ä¸Šä¼ æ–‡ä»¶
    upload_dir = os.path.join(settings.MEDIA_ROOT, 'uploaded_words')
    os.makedirs(upload_dir, exist_ok=True)
    input_file_path = os.path.join(upload_dir, uploaded_file.name)
    with open(input_file_path, 'wb') as f:
        for chunk in uploaded_file.chunks():
            f.write(chunk)

    # 4. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file_path, output_filename = generate_output_path(uploaded_file)
    print(output_filename)

    # 5. æ‰§è¡Œ AI æ ¼å¼åŒ–
    try:
        logger.info(f"å¼€å§‹æ ¼å¼åŒ–æ–‡ä»¶: {input_file_path}, è¾“å‡ºåˆ°: {output_file_path}")

        # Create log callback to send detailed AI logs to frontend
        def log_callback(message):
            """Callback to send AI processing logs to progress display"""
            add_processing_log(request, message)

        # è¯»å–é‡è¯•é…ç½®ç”¨äºä¼šè¯è·Ÿè¸ª
        retry_enabled = getattr(settings, 'ZHIPU_RETRY_ENABLED', True)
        retry_count = getattr(settings, 'ZHIPU_RETRY_COUNT', 1)

        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        request.session['ai_processing'] = {
            'status': 'processing',
            'attempt': 1,
            'max_attempts': retry_count + 1 if use_ai and retry_enabled else 1,
            'timestamp': datetime.now().isoformat()
        }
        request.session.save()

        formatter = AIWordFormatter(input_file_path, use_ai=use_ai, tone=tone, style_config=style_config, log_callback=log_callback)

        # åœ¨æ ¼å¼åŒ–å‰è·å–åŸå§‹æ–‡æ¡£åˆ†ææ•°æ®
        original_analysis = formatter.analyze_document()
        logger.info(f"åŸå§‹æ–‡æ¡£åˆ†æ: {original_analysis}")

        result = formatter.format(output_file_path)
        logger.info("æ–‡ä»¶æ ¼å¼åŒ–å®Œæˆ")

        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºæˆåŠŸ
        request.session['ai_processing']['status'] = 'complete'
        request.session['ai_processing']['completed_at'] = datetime.now().isoformat()
        request.session.save()

        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶æ˜¯å¦ä¸ºç©º
        if os.path.getsize(output_file_path) == 0:
            os.remove(output_file_path)
            raise ValueError("ç”Ÿæˆçš„æ–‡ä»¶ä¸ºç©ºï¼Œè¯·é‡è¯•")

        # è®°å½•åŸå§‹æ–‡ä»¶åå’Œç”Ÿæˆçš„æ–‡ä»¶å
        logger.info(f"åŸå§‹æ–‡ä»¶å: {uploaded_file.name}, ç”Ÿæˆæ–‡ä»¶å: {output_filename}")

        # è¿”å›æ–‡ä»¶ä¸‹è½½ï¼Œè®¾ç½®æ­£ç¡®çš„Content-Dispositionå¤´
        response = FileResponse(open(output_file_path, 'rb'))
        response['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        # ä½¿ç”¨å¼•å·åŒ…å›´æ–‡ä»¶åï¼Œç¡®ä¿æµè§ˆå™¨æ­£ç¡®å¤„ç†åŒ…å«ä¸­æ–‡çš„æ–‡ä»¶å

        from urllib.parse import quote  # å¯¼å…¥URLç¼–ç æ¨¡å—
        # 1. å¯¹æ–‡ä»¶ååšURLç¼–ç ï¼ˆè§£å†³ä¸­æ–‡/ç‰¹æ®Šå­—ç¬¦ï¼‰
        encoded_filename = quote(output_filename)
        response['Content-Disposition'] = (
            f'attachment; filename="{encoded_filename}"; '
            f'filename*=UTF-8\'\'{encoded_filename}'
        )

        return response

    except ValueError as ve:
        # AIè¿”å›ç©ºæˆ–æ–‡ä»¶ä¸ºç©ºçš„æƒ…å†µ
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºå¤±è´¥
        request.session['ai_processing'] = {
            'status': 'failed',
            'error': str(ve),
            'timestamp': datetime.now().isoformat()
        }
        request.session.save()

        # é‡æ–°åˆ›å»ºformatterä»¥è·å–åˆ†ææ•°æ®
        formatter = AIWordFormatter(input_file_path, use_ai=use_ai, tone=tone, style_config=style_config)
        original_analysis = formatter.analyze_document()
        return render(request, 'upload_word_ai.html', {
            'error': str(ve),
            'original_analysis': original_analysis
        })
    except Exception as e:
        # å…¶ä»–é”™è¯¯
        # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºå¤±è´¥
        request.session['ai_processing'] = {
            'status': 'failed',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }
        request.session.save()

        # å°è¯•åˆ›å»ºformatterä»¥è·å–åˆ†ææ•°æ®ï¼Œå³ä½¿å¤±è´¥ä¹Ÿè¦æ˜¾ç¤º
        try:
            formatter = AIWordFormatter(input_file_path, use_ai=use_ai, tone=tone, style_config=style_config)
            original_analysis = formatter.analyze_document()
        except:
            original_analysis = None
        return render(request, 'upload_word_ai.html', {
            'error': f"å¤„ç†å¤±è´¥ï¼š{str(e)}",
            'original_analysis': original_analysis
        })


def handle_template_optimization(request, uploaded_file):
    """
    Handle template-based optimization mode
    """
    from .services.template_manager import TemplateManager
    from .utils.ai_word_utils import AITextProcessor
    from .utils.image_tracker import DocumentImageTracker, ImageReinsertionStrategy
    from docx import Document
    import re

    logger.info("Processing template optimization mode")

    # Initialize processing logs
    add_processing_log(request, "å¼€å§‹æ¨¡æ¿ä¼˜åŒ–å¤„ç† / Starting template optimization")
    add_processing_log(request, f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {uploaded_file.name}")

    # Get template selection
    template_id = request.POST.get('template_id')
    if not template_id:
        error_msg = "è¯·é€‰æ‹©æ¨¡æ¿ / Please select a template"
        logger.warning(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    # Get template from TemplateManager
    template = TemplateManager.get_template(
        template_id,
        request.user if request.user.is_authenticated else None
    )

    if not template:
        error_msg = f"æ¨¡æ¿ '{template_id}' ä¸å­˜åœ¨"
        logger.warning(error_msg)
        add_processing_log(request, f"âŒ é”™è¯¯: {error_msg}")
        request.session['processing']['status'] = 'failed'
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    add_processing_log(request, f"åŠ è½½æ¨¡æ¿: {template.name}")

    # Get common settings
    tone = request.POST.get('tone', 'no_preference')
    style_template = request.POST.get('style_template', 'default')

    # Get style config (reused from simple mode logic)
    from format_specifications.utils.word_formatter import STYLE_TEMPLATES
    style_config = STYLE_TEMPLATES[style_template].copy()

    # Save uploaded file temporarily
    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
        for chunk in uploaded_file.chunks():
            tmp_file.write(chunk)
        tmp_file_path = tmp_file.name

    # Initialize image tracker
    image_tracker = DocumentImageTracker(tmp_file_path)
    extracted_images = []

    try:
        # Extract images with context BEFORE processing text
        try:
            extracted_images = image_tracker.extract_images_with_context()
            add_processing_log(request, f"æ£€æµ‹åˆ° {len(extracted_images)} å¼ å›¾ç‰‡ / Detected {len(extracted_images)} image(s)")
            logger.info(f"Extracted {len(extracted_images)} images from document")
        except Exception as e:
            logger.warning(f"Image extraction failed: {e}")
            add_processing_log(request, f"âš ï¸ å›¾ç‰‡æå–å¤±è´¥ / Image extraction failed: {str(e)}")

        # Extract text from uploaded document
        logger.info(f"Extracting text from document: {tmp_file_path}")
        add_processing_log(request, "æå–æ–‡æ¡£å†…å®¹... / Extracting document content")
        doc = Document(tmp_file_path)
        source_document_text = '\n'.join([para.text for para in doc.paragraphs if para.text.strip()])
        add_processing_log(request, f"æå–å®Œæˆ: {len(source_document_text)} å­—ç¬¦ / Extracted {len(source_document_text)} chars")

        if not source_document_text.strip():
            error_msg = "ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å¤„ç†"
            logger.warning(error_msg)
            return render(request, 'upload_word_ai.html', {'error': error_msg})

        logger.info(f"Extracted {len(source_document_text)} characters from source document")

        # Create log callback to send detailed AI logs to frontend
        def log_callback(message):
            """Callback to send AI processing logs to progress display"""
            add_processing_log(request, message)

        # Choose processing mode based on document size
        processor = AITextProcessor(tone=tone, log_callback=log_callback)

        if len(source_document_text) < 500:
            # Use batch mode for small documents
            logger.info(f"Small document ({len(source_document_text)} chars), using BATCH mode")
            add_processing_log(request, f"ä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼ / Using BATCH mode ({len(source_document_text)} chars)")
            generated_content = processor.generate_from_template_batch(
                template=template,
                source_document_text=source_document_text,
                user_outline="",
                tone=tone
            )
        else:
            # Use sequential mode for medium/large documents
            logger.info(f"Medium/Large document ({len(source_document_text)} chars), using SEQUENTIAL mode")
            add_processing_log(request, f"ä½¿ç”¨é¡ºåºå¤„ç†æ¨¡å¼ / Using SEQUENTIAL mode ({len(source_document_text)} chars)")
            add_processing_log(request, f"å¤„ç† {len(template.sections)} ä¸ªç« èŠ‚ / Processing {len(template.sections)} sections")
            generated_content = processor.generate_from_template(
                template=template,
                user_outline="",  # No user outline, use extracted content
                source_document_text=source_document_text,
                tone=tone
            )

        # Match extracted images to sections based on context
        image_insertions = []
        if extracted_images:
            add_processing_log(request, f"åŒ¹é…å›¾ç‰‡åˆ°ç« èŠ‚ / Matching images to sections ({len(extracted_images)} images)")
            for image_meta in extracted_images:
                section_id, position = ImageReinsertionStrategy.find_best_insertion_position(
                    image_meta,
                    generated_content,
                    template
                )
                image_insertions.append({
                    'section_id': section_id,
                    'image_path': image_meta['image_path'],
                    'position': position
                })
                logger.debug(f"Matched image to section: {section_id}")

            add_processing_log(request, f"å·²åŒ¹é… {len(image_insertions)} å¼ å›¾ç‰‡ / Matched {len(image_insertions)} image(s)")

        # Build document from generated content
        output_file_path, output_filename = generate_output_path(uploaded_file)
        output_doc = Document()

        # Get style config for image dimensions
        from docx.shared import Inches
        image_width = Inches(style_config['image_width'])
        image_height = Inches(style_config['image_height'])

        # Add title
        title = output_doc.add_heading(template.name, 0)
        title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

        # Helper function to check if content is meaningful (not placeholder or too short)
        def is_meaningful_content(content: str) -> bool:
            """Check if content has meaningful text (not just placeholders)"""
            if not content or not isinstance(content, str):
                return False

            content = content.strip()

            # Check if too short (less than 15 characters)
            if len(content) < 15:
                return False

            # Check for placeholder patterns
            placeholders = [
                '[å¾…è¡¥å……]', '[å¾…å¡«å†™]', '[å¾…å®Œå–„]',
                'å¾…è¡¥å……', 'å¾…å¡«å†™', 'å¾…å®Œå–„',
                'è¯·è¡¥å……', 'è¯·å¡«å†™', 'è¯·å®Œå–„'
            ]

            # If content is mostly placeholders, it's not meaningful
            placeholder_count = sum(1 for p in placeholders if p in content)
            if placeholder_count > 0:
                # Calculate what percentage of content is placeholders
                total_placeholder_chars = sum(len(p) for p in placeholders if p in content)
                if total_placeholder_chars / len(content) > 0.3:  # More than 30% placeholders
                    return False

            return True

        # Debug logging
        logger.info(f"Filtering and writing sections (only meaningful content)")
        sections_written = 0
        sections_skipped = 0

        # Add sections based on template structure
        for section in template.sections:
            # Check if main section has meaningful content
            section_has_content = False
            section_content = None

            if section.id in generated_content:
                section_content = generated_content[section.id]
                if is_meaningful_content(section_content):
                    section_has_content = True

            # Check if any subsection has meaningful content
            subsections_with_content = []
            for subsection in section.subsections:
                if subsection.id in generated_content:
                    subsection_content = generated_content[subsection.id]
                    if is_meaningful_content(subsection_content):
                        subsections_with_content.append((subsection, subsection_content))

            # Only write section if it has content OR has subsections with content
            if section_has_content or subsections_with_content:
                # Write main section heading and content (if exists)
                if section_has_content:
                    output_doc.add_heading(section.title, 1)
                    # âœ… ä¿®å¤ï¼šæ·»åŠ æ®µè½æ ·å¼è®¾ç½®ï¼ŒåŒ…æ‹¬é¦–è¡Œç¼©è¿›
                    content_para = output_doc.add_paragraph(section_content)
                    from docx.oxml.ns import qn
                    content_para.paragraph_format.line_spacing = 1.5
                    content_para.paragraph_format.first_line_indent = Pt(21.0)
                    # Set font properties
                    for run in content_para.runs:
                        run.font.name = 'å®‹ä½“'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                        run.font.size = Pt(12)
                    logger.info(f"âœ“ Wrote section: {section.title} ({len(section_content)} chars)")
                    sections_written += 1

                    # Insert images matched to this section
                    section_images = [img for img in image_insertions if img['section_id'] == section.id]
                    for img_data in section_images:
                        from docx.shared import Pt
                        img_para = output_doc.add_paragraph()
                        img_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                        img_para.paragraph_format.space_after = Pt(12)
                        img_para.paragraph_format.space_before = Pt(12)

                        try:
                            img_run = img_para.add_run()
                            img_run.add_picture(
                                img_data['image_path'],
                                width=image_width,
                                height=image_height
                            )
                            logger.info(f"  âœ“ Inserted image in section: {section.title}")
                        except Exception as e:
                            logger.warning(f"  âœ— Failed to insert image: {e}")
                            img_para.add_run("[å›¾ç‰‡åŠ è½½å¤±è´¥ / Image load failed]")
                elif subsections_with_content:
                    # Section has no main content but has subsections - write heading only
                    output_doc.add_heading(section.title, 1)
                    logger.info(f"âœ“ Wrote section heading (no main content): {section.title}")
                    sections_written += 1

                # Write subsections with meaningful content
                for subsection, subsection_content in subsections_with_content:
                    output_doc.add_heading(subsection.title, 2)
                    # âœ… ä¿®å¤ï¼šæ·»åŠ æ®µè½æ ·å¼è®¾ç½®ï¼ŒåŒ…æ‹¬é¦–è¡Œç¼©è¿›
                    subsection_para = output_doc.add_paragraph(subsection_content)
                    from docx.oxml.ns import qn
                    subsection_para.paragraph_format.line_spacing = 1.5
                    subsection_para.paragraph_format.first_line_indent = Pt(21.0)
                    # Set font properties
                    for run in subsection_para.runs:
                        run.font.name = 'å®‹ä½“'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                        run.font.size = Pt(12)
                    logger.info(f"  âœ“ Wrote subsection: {subsection.title} ({len(subsection_content)} chars)")
            else:
                # Skip this section entirely - no title, no content
                logger.info(f"âŠ˜ Skipping section (no meaningful content): {section.title}")
                sections_skipped += 1

        logger.info(f"Document generation complete: {sections_written} sections written, {sections_skipped} sections skipped")

        # Save document
        add_processing_log(request, f"âœ… ç”Ÿæˆæ–‡æ¡£å®Œæˆ / Document generated ({sections_written} sections written)")
        request.session['processing']['status'] = 'complete'
        output_doc.save(output_file_path)
        logger.info(f"Generated document saved to: {output_file_path}")

        # Return file response
        response = FileResponse(open(output_file_path, 'rb'))
        response['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'

        from urllib.parse import quote
        encoded_filename = quote(output_filename)
        response['Content-Disposition'] = (
            f'attachment; filename="{encoded_filename}"; '
            f'filename*=UTF-8\'\'{encoded_filename}'
        )

        return response

    except Exception as e:
        logger.error(f"Template optimization failed: {str(e)}")
        error_msg = f"æ¨¡æ¿ä¼˜åŒ–å¤±è´¥: {str(e)}"
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    finally:
        # Clean up temporary file
        if os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

        # Clean up extracted images
        image_tracker.cleanup()


def find_best_custom_section_for_image(image_metadata: dict, structure_sections: list) -> str:
    """
    Find the best section title to insert an image for custom structure mode.

    Uses a multi-strategy approach:
    1. Primary: Keyword relevance scoring against section titles
    2. Fallback 1: First section with substantial content (>100 chars)
    3. Fallback 2: Last section
    4. Last resort: First section

    Args:
        image_metadata: Image context from original document
        structure_sections: List of section dicts with 'title' keys

    Returns:
        Section title to insert image into (None if no match)
    """
    from typing import List, Dict

    best_section = None
    best_score = 0.0

    # Try to match based on keywords in section titles
    for section in structure_sections:
        section_title = section['title']

        # Calculate relevance score
        score = 0.0

        # Check section title against preceding text
        if section_title.lower() in image_metadata['preceding_text'].lower():
            score += 0.5

        # Check section title against following text
        if section_title.lower() in image_metadata['following_text'].lower():
            score += 0.5

        # Check section title against paragraph text
        if section_title.lower() in image_metadata['paragraph_text'].lower():
            score += 0.3

        if score > best_score:
            best_score = score
            best_section = section_title

    # If best match found and has meaningful score
    if best_section and best_score > 0:
        return best_section

    # Fallback: first section (if any sections exist)
    if structure_sections and len(structure_sections) > 0:
        return structure_sections[0]['title']

    return None


def handle_custom_optimization(request, uploaded_file):
    """
    Handle custom structure optimization mode
    """
    from .utils.ai_word_utils import AITextProcessor
    from .utils.image_tracker import DocumentImageTracker
    from docx import Document
    from docx.shared import Pt
    import re

    logger.info("Processing custom structure optimization mode")

    # Get custom structure points
    custom_structure = request.POST.get('custom_structure', '').strip()

    if not custom_structure:
        error_msg = "è¯·è¾“å…¥è‡ªå®šä¹‰ç»“æ„è¦ç‚¹"
        logger.warning(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    # Parse structure points
    structure_sections = parse_custom_structure(custom_structure)
    logger.info(f"Parsed {len(structure_sections)} structure sections")

    if not structure_sections:
        error_msg = "æ— æ³•è§£æè‡ªå®šä¹‰ç»“æ„ï¼Œè¯·ç¡®ä¿æ¯è¡Œä¸€ä¸ªç»“æ„è¦ç‚¹"
        logger.warning(error_msg)
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    # Get common settings
    tone = request.POST.get('tone', 'no_preference')
    style_template = request.POST.get('style_template', 'default')

    # Get style config
    from format_specifications.utils.word_formatter import STYLE_TEMPLATES
    style_config = STYLE_TEMPLATES[style_template].copy()

    # Save uploaded file temporarily
    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
        for chunk in uploaded_file.chunks():
            tmp_file.write(chunk)
        tmp_file_path = tmp_file.name

    # Initialize image tracker
    image_tracker = DocumentImageTracker(tmp_file_path)
    extracted_images = []

    try:
        # Extract images with context BEFORE processing text
        try:
            extracted_images = image_tracker.extract_images_with_context()
            logger.info(f"Extracted {len(extracted_images)} images from document")
            add_processing_log(request, f"æ£€æµ‹åˆ° {len(extracted_images)} å¼ å›¾ç‰‡ / Detected {len(extracted_images)} image(s)")
        except Exception as e:
            logger.warning(f"Image extraction failed: {e}")
            add_processing_log(request, f"âš ï¸ å›¾ç‰‡æå–å¤±è´¥ / Image extraction failed: {str(e)}")

        # Extract text from uploaded document
        logger.info(f"Extracting text from document: {tmp_file_path}")
        doc = Document(tmp_file_path)
        source_document_text = '\n'.join([para.text for para in doc.paragraphs if para.text.strip()])

        if not source_document_text.strip():
            error_msg = "ä¸Šä¼ çš„æ–‡æ¡£å†…å®¹ä¸ºç©ºï¼Œæ— æ³•å¤„ç†"
            logger.warning(error_msg)
            return render(request, 'upload_word_ai.html', {'error': error_msg})

        # Create log callback to send detailed AI logs to frontend
        def log_callback(message):
            """Callback to send AI processing logs to progress display"""
            add_processing_log(request, message)

        # Generate content according to custom structure
        processor = AITextProcessor(tone=tone, log_callback=log_callback)
        generated_content = generate_with_custom_structure(
            processor,
            source_document_text,
            structure_sections
        )

        # Match extracted images to sections based on context
        image_insertions = []
        if extracted_images:
            add_processing_log(request, f"ğŸ“· åŒ¹é…å›¾ç‰‡åˆ°ç« èŠ‚ / Matching images to sections ({len(extracted_images)} images)")
            logger.info(f"Starting image matching for {len(extracted_images)} images to {len(structure_sections)} sections")

            for idx, image_meta in enumerate(extracted_images):
                section_title = find_best_custom_section_for_image(
                    image_meta,
                    structure_sections
                )
                if section_title:
                    image_insertions.append({
                        'section_title': section_title,
                        'image_path': image_meta['image_path']
                    })
                    logger.info(f"  Image {idx + 1}: matched to section '{section_title}' (context: '{image_meta['paragraph_text'][:50]}')")
                else:
                    logger.warning(f"  Image {idx + 1}: no matching section found (context: '{image_meta['paragraph_text'][:50]}')")

            logger.info(f"Image matching complete: {len(image_insertions)}/{len(extracted_images)} images matched")
            add_processing_log(request, f"âœ… å·²åŒ¹é… {len(image_insertions)} å¼ å›¾ç‰‡ / Matched {len(image_insertions)} image(s)")
        else:
            logger.warning("No extracted images to match")
            add_processing_log(request, "âš ï¸ æœªæ£€æµ‹åˆ°å›¾ç‰‡ / No images detected")

        # Build document
        output_file_path, output_filename = generate_output_path(uploaded_file)
        output_doc = Document()

        # Get style config for image dimensions
        from docx.shared import Inches
        image_width = Inches(style_config['image_width'])
        image_height = Inches(style_config['image_height'])
        logger.info(f"Image dimensions: {style_config['image_width']}\" x {style_config['image_height']}\"")

        # Add title
        title = output_doc.add_heading('è‡ªå®šä¹‰ç»“æ„æ–‡æ¡£', 0)
        title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

        # Add sections based on custom structure
        sections_with_images = 0
        total_images_inserted = 0

        for section in structure_sections:
            section_title = section['title']
            # âœ… ä¿®å¤ï¼šå³ä½¿å†…å®¹ä¸ºç©ºï¼Œä¹Ÿæ·»åŠ ç« èŠ‚æ ‡é¢˜å’Œå›¾ç‰‡
            if section_title in generated_content:
                section_content = generated_content[section_title]

                # Add section heading (always add if section exists)
                output_doc.add_heading(section_title, 1)

                # Add section content with proper formatting
                if section_content and section_content.strip():
                    content_para = output_doc.add_paragraph(section_content)
                    # âœ… ä¿®å¤ï¼šåº”ç”¨æ®µè½æ ·å¼ï¼ŒåŒ…æ‹¬é¦–è¡Œç¼©è¿›2æ ¼ï¼ˆ21ç£…ï¼‰
                    from docx.oxml.ns import qn
                    content_para.paragraph_format.line_spacing = 1.5
                    content_para.paragraph_format.first_line_indent = Pt(21.0)

                    # Set font properties for content
                    for run in content_para.runs:
                        run.font.name = 'å®‹ä½“'
                        run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                        run.font.size = Pt(12)

                # Insert images matched to this section (even if content is empty)
                section_images = [img for img in image_insertions if img['section_title'] == section_title]
                if section_images:
                    sections_with_images += 1
                    logger.info(f"Section '{section_title}': inserting {len(section_images)} image(s)")

                for img_idx, img_data in enumerate(section_images):
                    img_para = output_doc.add_paragraph()
                    img_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                    img_para.paragraph_format.space_after = Pt(12)
                    img_para.paragraph_format.space_before = Pt(12)

                    try:
                        img_run = img_para.add_run()
                        img_run.add_picture(
                            img_data['image_path'],
                            width=image_width,
                            height=image_height
                        )
                        total_images_inserted += 1
                        logger.info(f"  âœ“ Inserted image {img_idx + 1} in section: {section_title}")
                        add_processing_log(request, f"  âœ“ æ’å…¥å›¾ç‰‡åˆ°: {section_title} / Inserted image in: {section_title}")
                    except Exception as e:
                        logger.warning(f"  âœ— Failed to insert image: {e}")
                        img_para.add_run("[å›¾ç‰‡åŠ è½½å¤±è´¥ / Image load failed]")

        # Save document
        logger.info(f"Document generation complete:")
        logger.info(f"  - Sections with images: {sections_with_images}/{len(structure_sections)}")
        logger.info(f"  - Total images inserted: {total_images_inserted}/{len(extracted_images)}")

        output_doc.save(output_file_path)
        logger.info(f"Generated document saved to: {output_file_path}")

        # Return file response
        response = FileResponse(open(output_file_path, 'rb'))
        response['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'

        from urllib.parse import quote
        encoded_filename = quote(output_filename)
        response['Content-Disposition'] = (
            f'attachment; filename="{encoded_filename}"; '
            f'filename*=UTF-8\'\'{encoded_filename}'
        )

        return response

    except Exception as e:
        logger.error(f"Custom structure optimization failed: {str(e)}")
        error_msg = f"è‡ªå®šä¹‰ç»“æ„ä¼˜åŒ–å¤±è´¥: {str(e)}"
        return render(request, 'upload_word_ai.html', {'error': error_msg})

    finally:
        # Clean up temporary file
        if os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

        # Clean up extracted images
        image_tracker.cleanup()


def parse_custom_structure(structure_text):
    """
    Parse user's custom structure into sections
    Supports:
    - Numbered list: 1. Title, 2. Title
    - Plain lines: Just text (treat as section title)
    """
    lines = structure_text.strip().split('\n')
    sections = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # Remove numbering if present
        clean_title = line
        if line[0].isdigit() and ('.' in line or ')' in line or 'ã€' in line):
            # Extract title after number
            parts = re.split(r'^[\d]+[\.\ï¼‰ã€]\s*', line, 1)
            if len(parts) > 1:
                clean_title = parts[1]

        sections.append({
            'title': clean_title,
            'original': line
        })

    return sections


def generate_with_custom_structure(processor, source_text, structure_sections):
    """
    Generate document content organized by custom structure
    """
    generated_content = {}

    for section in structure_sections:
        # Extract content relevant to this section
        extracted = processor.extract_section_for_structure(
            source_text,
            section['title']
        )

        # Fallback: if extraction failed, use first 1000 chars of source text
        if not extracted or not extracted.strip():
            logger.warning(f"Extraction failed for section '{section['title']}', using fallback")
            extracted = source_text[:1000]

        logger.info(f"Extracted {len(extracted) if extracted else 0} chars for section: {section['title']}")

        # Polish the extracted content
        if extracted and extracted.strip() and len(extracted.strip()) > 10:
            logger.info(f"Polishing content for section: {section['title']}")
            polished = processor.process_text(extracted)
            generated_content[section['title']] = polished
            logger.info(f"Polished content: {len(polished)} chars")
        else:
            logger.warning(f"Section {section['title']} has no meaningful content, skipping polishing")
            generated_content[section['title']] = ""

    return generated_content


@require_http_methods(["GET"])
def ai_processing_status(request):
    """
    è¿”å› AI å¤„ç†çŠ¶æ€ï¼Œç”¨äºå‰ç«¯è½®è¯¢

    æ€§èƒ½ä¼˜åŒ–ï¼š
    - ä¸è°ƒç”¨ AI APIï¼Œä»…è¯»å– session
    - å“åº”æ—¶é—´ < 10ms
    - å‰ç«¯è½®è¯¢é—´éš” >= 4 ç§’
    """
    # å¿«é€Ÿè¿”å› session ä¸­çš„çŠ¶æ€ï¼ˆä¸æ¶‰åŠä»»ä½• AI è°ƒç”¨ï¼‰
    processing_info = request.session.get('ai_processing', {
        'status': 'unknown'
    })

    # æ·»åŠ å“åº”å¤´ï¼Œé˜²æ­¢æµè§ˆå™¨ç¼“å­˜
    response = JsonResponse(processing_info)
    response['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    response['Pragma'] = 'no-cache'
    response['Expires'] = '0'

    return response


@require_http_methods(["GET"])
def processing_status(request):
    """
    è¿”å›é€šç”¨å¤„ç†çŠ¶æ€ï¼Œç”¨äºå‰ç«¯è½®è¯¢ï¼ˆæ”¯æŒæ‰€æœ‰ä¼˜åŒ–æ¨¡å¼ï¼‰

    æ€§èƒ½ä¼˜åŒ–ï¼š
    - ä¸è°ƒç”¨ AI APIï¼Œä»…è¯»å– session
    - å“åº”æ—¶é—´ < 10ms
    - å‰ç«¯è½®è¯¢é—´éš” 2 ç§’
    """
    # å¿«é€Ÿè¿”å› session ä¸­çš„å¤„ç†çŠ¶æ€ï¼ˆä¸æ¶‰åŠä»»ä½• AI è°ƒç”¨ï¼‰
    processing_info = request.session.get('processing', {
        'status': 'unknown',
        'logs': [],
        'current_step': 0,
        'total_steps': 0
    })

    # æ·»åŠ å“åº”å¤´ï¼Œé˜²æ­¢æµè§ˆå™¨ç¼“å­˜
    response = JsonResponse(processing_info)
    response['Cache-Control'] = 'no-store, no-cache, must-revalidate, max-age=0'
    response['Pragma'] = 'no-cache'
    response['Expires'] = '0'

    return response


# ==================== æ–‡æ¡£åˆ†å‰²åŠŸèƒ½ (Document Segmentation) ====================

def segmentation_only_page(request):
    """
    æ¸²æŸ“æ–‡æ¡£åˆ†å‰²é¡µé¢
    """
    logger.info("è®¿é—®æ–‡æ¡£åˆ†å‰²é¡µé¢")
    return render(request, 'segmentation_only.html')


@require_http_methods(["POST"])
def segment_document(request):
    """
    å¤„ç†æ–‡æ¡£åˆ†å‰²è¯·æ±‚

    å‚æ•°:
    - document: ä¸Šä¼ çš„Wordæ–‡æ¡£
    - mode: åˆ†å‰²æ¨¡å¼ (paragraph/sentence/semantic)
    - include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ® (å¯é€‰)

    è¿”å›:
    - åˆ†å‰²åçš„Wordæ–‡æ¡£ä¸‹è½½
    """
    logger.info("å¼€å§‹å¤„ç†æ–‡æ¡£åˆ†å‰²è¯·æ±‚")

    # 1. éªŒè¯æ–‡ä»¶ä¸Šä¼ 
    if 'document' not in request.FILES:
        error_msg = "è¯·ä¸Šä¼ Wordæ–‡æ¡£"
        logger.warning(error_msg)
        return render(request, 'segmentation_only.html', {'error': error_msg})

    uploaded_file = request.FILES['document']
    if not uploaded_file.name.endswith('.docx'):
        error_msg = "ä»…æ”¯æŒ .docx æ ¼å¼"
        logger.warning(error_msg)
        return render(request, 'segmentation_only.html', {'error': error_msg})

    # 2. è·å–åˆ†å‰²å‚æ•°
    mode = request.POST.get('mode', 'paragraph')
    include_metadata = request.POST.get('include_metadata') == 'on'

    # éªŒè¯åˆ†å‰²æ¨¡å¼
    valid_modes = ['paragraph', 'sentence', 'semantic']
    if mode not in valid_modes:
        error_msg = f"æ— æ•ˆçš„åˆ†å‰²æ¨¡å¼: {mode}"
        logger.warning(error_msg)
        return render(request, 'segmentation_only.html', {'error': error_msg})

    logger.info(f"åˆ†å‰²æ¨¡å¼: {mode}, åŒ…å«å…ƒæ•°æ®: {include_metadata}")

    # 3. ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
            for chunk in uploaded_file.chunks():
                tmp_file.write(chunk)
            tmp_file_path = tmp_file.name

        logger.info(f"æ–‡ä»¶å·²ä¿å­˜åˆ°ä¸´æ—¶ä½ç½®: {tmp_file_path}")

        # 4. æå–æ–‡æ¡£æ–‡æœ¬
        doc = Document(tmp_file_path)
        paragraphs = []
        for para in doc.paragraphs:
            text = para.text.strip()
            if text:  # è·³è¿‡ç©ºæ®µè½
                paragraphs.append(text)

        full_text = "\n\n".join(paragraphs)
        logger.info(f"æå–äº† {len(paragraphs)} ä¸ªæ®µè½ï¼Œå…± {len(full_text)} ä¸ªå­—ç¬¦")

        # 5. è°ƒç”¨åˆ†å‰²æ–¹æ³•
        processor = AITextProcessor()

        if include_metadata:
            segments = processor.segment_text(full_text, mode=mode, include_metadata=True)
            logger.info(f"åˆ†å‰²å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰")
        else:
            segments = processor.segment_text(full_text, mode=mode, include_metadata=False)
            logger.info(f"åˆ†å‰²å®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")

        # 6. æ„å»ºè¾“å‡ºæ–‡æ¡£
        output_filename = f"segmented_{mode}_{uploaded_file.name}"

        # Create output directory
        output_dir = os.path.join(settings.MEDIA_ROOT, 'segmented')
        os.makedirs(output_dir, exist_ok=True)

        # Generate output path
        output_path = os.path.join(output_dir, output_filename)

        _build_segmented_document(segments, mode, include_metadata, output_path)
        logger.info(f"åˆ†å‰²æ–‡æ¡£å·²ä¿å­˜åˆ°: {output_path}")

        # 7. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            os.unlink(tmp_file_path)
        except:
            pass

        # 8. è¿”å›æ–‡ä»¶
        response = FileResponse(open(output_path, 'rb'))
        response['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        response['Content-Disposition'] = f'attachment; filename="{output_filename}"'

        return response

    except Exception as e:
        logger.error(f"æ–‡æ¡£åˆ†å‰²å¤±è´¥: {str(e)}", exc_info=True)
        error_msg = f"åˆ†å‰²å¤±è´¥: {str(e)}"
        return render(request, 'segmentation_only.html', {'error': error_msg})


def _build_segmented_document(segments, mode, include_metadata, output_path):
    """
    æ„å»ºåˆ†å‰²åçš„Wordæ–‡æ¡£

    å‚æ•°:
    - segments: åˆ†å‰²åçš„ç‰‡æ®µåˆ—è¡¨æˆ–å­—å…¸åˆ—è¡¨
    - mode: åˆ†å‰²æ¨¡å¼
    - include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®
    - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    doc = Document()

    # æ·»åŠ æ ‡é¢˜
    title_text = {
        'paragraph': 'æ–‡æ¡£åˆ†å‰²ç»“æœ - æŒ‰æ®µè½åˆ†å‰²',
        'sentence': 'æ–‡æ¡£åˆ†å‰²ç»“æœ - æŒ‰å¥å­åˆ†å‰²',
        'semantic': 'æ–‡æ¡£åˆ†å‰²ç»“æœ - æŒ‰è¯­ä¹‰åˆ†å‰²'
    }

    title = doc.add_heading(title_text.get(mode, 'æ–‡æ¡£åˆ†å‰²ç»“æœ'), 0)
    title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

    # æ·»åŠ åˆ†å‰²ä¿¡æ¯
    info_para = doc.add_paragraph()
    info_para.add_run(f"åˆ†å‰²æ¨¡å¼: {mode}\n")
    info_para.add_run(f"ç‰‡æ®µæ•°é‡: {len(segments)}\n")
    info_para.add_run(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    info_para.runs[0].font.size = Pt(10)
    info_para.runs[0].font.color.rgb = None  # ä½¿ç”¨é»˜è®¤ç°è‰²

    # æ·»åŠ åˆ†éš”çº¿
    doc.add_paragraph("_" * 80)

    # æ·»åŠ æ¯ä¸ªç‰‡æ®µ
    if include_metadata:
        # åŒ…å«å…ƒæ•°æ®çš„æ ¼å¼
        for i, segment in enumerate(segments, 1):
            # å…ƒæ•°æ®ä¿¡æ¯
            meta_para = doc.add_paragraph()
            meta_para.add_run(f"[ç‰‡æ®µ {i}]").bold = True
            meta_para.add_run(f" ç±»å‹: {segment.get('type', mode)} | ")
            meta_para.add_run(f"ä½ç½®: {segment.get('position', i-1)}")
            meta_para.runs[0].font.size = Pt(9)
            meta_para.runs[0].font.color.rgb = None

            # ç‰‡æ®µå†…å®¹
            content_para = doc.add_paragraph(segment.get('text', ''))
            content_para.runs[0].font.size = Pt(11)

            # ç‰‡æ®µé—´ç©ºè¡Œ
            doc.add_paragraph()
    else:
        # ç®€å•æ ¼å¼ï¼Œåªæ˜¾ç¤ºæ–‡æœ¬
        for i, segment in enumerate(segments, 1):
            if isinstance(segment, str):
                # çº¯æ–‡æœ¬ç‰‡æ®µ
                content_para = doc.add_paragraph(f"[{i}] {segment}")
                content_para.runs[0].font.size = Pt(11)
            else:
                # å­—å…¸å½¢å¼ï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
                content_para = doc.add_paragraph(f"[{i}] {segment.get('text', segment)}")
                content_para.runs[0].font.size = Pt(11)

    # ä¿å­˜æ–‡æ¡£
    doc.save(output_path)
    logger.info(f"æ–‡æ¡£æ„å»ºå®Œæˆï¼Œå…± {len(segments)} ä¸ªç‰‡æ®µ")


# ==================== æ¨¡æ¿ç”ŸæˆåŠŸèƒ½ (Template-Based Generation) ====================

def template_generation_page(request):
    """
    æ¸²æŸ“æ¨¡æ¿ç”Ÿæˆé¡µé¢
    """
    logger.info("è®¿é—®æ¨¡æ¿ç”Ÿæˆé¡µé¢")

    from format_specifications.services.template_manager import TemplateManager

    # Get all available templates
    user = request.user if request.user.is_authenticated else None
    templates = TemplateManager.list_available_templates(user)

    return render(request, 'template_generation.html', {
        'templates': templates
    })


@require_http_methods(["POST"])
def generate_from_template(request):
    """
    å¤„ç†æ¨¡æ¿ç”Ÿæˆè¯·æ±‚

    å‚æ•°:
    - template_id: é€‰æ‹©çš„æ¨¡æ¿ID
    - user_outline: ç”¨æˆ·æä¾›çš„è¦ç‚¹/å¤§çº²
    - source_document: å¯é€‰çš„æºæ–‡æ¡£
    - tone: å¯é€‰çš„è¯­è°ƒå‚æ•°

    è¿”å›:
    - ç”Ÿæˆçš„Wordæ–‡æ¡£ä¸‹è½½
    """
    logger.info("å¼€å§‹å¤„ç†æ¨¡æ¿ç”Ÿæˆè¯·æ±‚")

    from format_specifications.services.template_manager import TemplateManager
    from format_specifications.utils.document_extractor import DocumentExtractor
    from .utils.image_tracker import DocumentImageTracker, ImageReinsertionStrategy

    start_time = datetime.now()
    image_tracker = None
    tmp_file_path = None

    try:
        # 1. è·å–æ¨¡æ¿ID
        template_id = request.POST.get('template_id')
        if not template_id:
            error_msg = "è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡æ¿"
            logger.warning(error_msg)
            return render(request, 'template_generation.html', {'error': error_msg})

        # 2. è·å–ç”¨æˆ·è¦ç‚¹
        user_outline = request.POST.get('user_outline', '').strip()
        if not user_outline:
            error_msg = "è¯·æä¾›æ–‡æ¡£è¦ç‚¹"
            logger.warning(error_msg)
            return render(request, 'template_generation.html', {'error': error_msg})

        # 3. è·å–å¯é€‰çš„æºæ–‡æ¡£
        source_document_text = None
        had_source_document = False
        extracted_images = []

        if 'source_document' in request.FILES and request.FILES['source_document']:
            uploaded_file = request.FILES['source_document']

            if uploaded_file.name.endswith('.docx'):
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
                    for chunk in uploaded_file.chunks():
                        tmp_file.write(chunk)
                    tmp_file_path = tmp_file.name

                # æå–æ–‡æœ¬
                try:
                    source_document_text = DocumentExtractor.extract_full_text(tmp_file_path)
                    had_source_document = True
                    logger.info(f"æºæ–‡æ¡£å·²æå–ï¼Œå…± {len(source_document_text)} ä¸ªå­—ç¬¦")
                except Exception as e:
                    logger.warning(f"Failed to extract text from source document: {e}")

                # æå–å›¾ç‰‡
                try:
                    image_tracker = DocumentImageTracker(tmp_file_path)
                    extracted_images = image_tracker.extract_images_with_context()
                    logger.info(f"ä»æºæ–‡æ¡£æå–äº† {len(extracted_images)} å¼ å›¾ç‰‡")
                except Exception as e:
                    logger.warning(f"å›¾ç‰‡æå–å¤±è´¥: {str(e)}")

        # 4. è·å–è¯­è°ƒ
        tone = request.POST.get('tone', 'no_preference')

        # 5. è·å–æ¨¡æ¿
        user = request.user if request.user.is_authenticated else None
        template = TemplateManager.get_template(template_id, user)

        if not template:
            error_msg = f"æ¨¡æ¿ '{template_id}' ä¸å­˜åœ¨"
            logger.warning(error_msg)
            return render(request, 'template_generation.html', {'error': error_msg})

        # 6. ç”Ÿæˆå†…å®¹
        logger.info(f"å¼€å§‹ç”Ÿæˆæ–‡æ¡£: æ¨¡æ¿={template.name}, è¯­è°ƒ={tone}")
        processor = AITextProcessor(tone=tone)

        generated_content = processor.generate_from_template(
            template=template,
            user_outline=user_outline,
            source_document_text=source_document_text,
            tone=tone
        )

        logger.info(f"å†…å®¹ç”Ÿæˆå®Œæˆï¼Œå…± {len(generated_content)} ä¸ªç« èŠ‚")

        # 7. è·å–æ ·å¼é…ç½® (ç”¨äºå›¾ç‰‡å°ºå¯¸)
        from format_specifications.utils.word_formatter import STYLE_TEMPLATES
        style_template = request.POST.get('style_template', 'default')
        style_config = STYLE_TEMPLATES[style_template].copy()

        # 8. æ„å»ºWordæ–‡æ¡£
        output_filename = f"{template.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"

        # Create output directory
        output_dir = os.path.join(settings.MEDIA_ROOT, 'generated_from_template')
        os.makedirs(output_dir, exist_ok=True)

        # Generate output path
        output_path = os.path.join(output_dir, output_filename)

        _build_document_from_template(template, generated_content, output_path, extracted_images=extracted_images, style_config=style_config)
        logger.info(f"æ–‡æ¡£å·²ç”Ÿæˆ: {output_path}")

        # 9. è®¡ç®—è€—æ—¶
        duration = int((datetime.now() - start_time).total_seconds())

        # 10. è®°å½•ä½¿ç”¨æ—¥å¿—
        try:
            TemplateManager.log_template_usage(
                template=template,
                user=user,
                user_outline=user_outline,
                had_source_document=had_source_document,
                generation_success=True,
                generation_duration=duration
            )
        except Exception as e:
            logger.warning(f"è®°å½•ä½¿ç”¨æ—¥å¿—å¤±è´¥: {str(e)}")

        # 11. è¿”å›æ–‡ä»¶
        response = FileResponse(open(output_path, 'rb'))
        response['Content-Type'] = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'

        from urllib.parse import quote
        encoded_filename = quote(output_filename)
        response['Content-Disposition'] = (
            f'attachment; filename="{encoded_filename}"; '
            f'filename*=UTF-8\'\'{encoded_filename}'
        )

        return response

    except Exception as e:
        logger.error(f"æ¨¡æ¿ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)

        # è®°å½•å¤±è´¥æ—¥å¿—
        duration = int((datetime.now() - start_time).total_seconds())
        try:
            user = request.user if request.user.is_authenticated else None
            TemplateManager.log_template_usage(
                template=None,
                user=user,
                user_outline=request.POST.get('user_outline', ''),
                had_source_document='source_document' in request.FILES,
                generation_success=False,
                error_message=str(e),
                generation_duration=duration
            )
        except:
            pass

        error_msg = f"ç”Ÿæˆå¤±è´¥: {str(e)}"
        return render(request, 'template_generation.html', {'error': error_msg})

    finally:
        # Clean up temporary file
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.unlink(tmp_file_path)
            except:
                pass

        # Clean up extracted images
        if image_tracker:
            try:
                image_tracker.cleanup()
            except:
                pass


@require_http_methods(["GET"])
def api_template_details(request, template_id):
    """
    AJAXç«¯ç‚¹ï¼šè·å–æ¨¡æ¿è¯¦ç»†ä¿¡æ¯

    å‚æ•°:
    - template_id: æ¨¡æ¿ID

    è¿”å›:
    - JSONæ ¼å¼çš„æ¨¡æ¿è¯¦ç»†ä¿¡æ¯
    """
    logger.info(f"è·å–æ¨¡æ¿è¯¦æƒ…: {template_id}")

    from format_specifications.services.template_manager import TemplateManager

    try:
        user = request.user if request.user.is_authenticated else None
        template_dict = TemplateManager.get_template_details_dict(template_id, user)

        if not template_dict:
            return JsonResponse({
                'success': False,
                'error': f"æ¨¡æ¿ '{template_id}' ä¸å­˜åœ¨"
            }, status=404)

        return JsonResponse({
            'success': True,
            'template': template_dict
        })

    except Exception as e:
        logger.error(f"è·å–æ¨¡æ¿è¯¦æƒ…å¤±è´¥: {str(e)}", exc_info=True)
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=500)


def _build_document_from_template(template, generated_content, output_path, extracted_images=None, style_config=None):
    """
    æ ¹æ®æ¨¡æ¿å’Œç”Ÿæˆçš„å†…å®¹æ„å»ºWordæ–‡æ¡£

    å‚æ•°:
    - template: æ¨¡æ¿å¯¹è±¡
    - generated_content: å­—å…¸ï¼Œkeyä¸ºsection_idï¼Œvalueä¸ºç”Ÿæˆçš„å†…å®¹
    - output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    - extracted_images: æå–çš„å›¾ç‰‡å…ƒæ•°æ®åˆ—è¡¨ (å¯é€‰)
    - style_config: æ ·å¼é…ç½®ï¼Œç”¨äºå›¾ç‰‡å°ºå¯¸ (å¯é€‰)
    """
    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
    from .utils.image_tracker import ImageReinsertionStrategy
    from docx.shared import Inches

    doc = Document()

    # åŒ¹é…å›¾ç‰‡åˆ°ç« èŠ‚
    image_insertions = []
    if extracted_images:
        for image_meta in extracted_images:
            section_id, position = ImageReinsertionStrategy.find_best_insertion_position(
                image_meta,
                generated_content,
                template
            )
            if section_id:
                image_insertions.append({
                    'section_id': section_id,
                    'image_path': image_meta['image_path']
                })
                logger.debug(f"Matched image to section: {section_id}")

        logger.info(f"Matched {len(image_insertions)} images to sections")

    # è·å–å›¾ç‰‡å°ºå¯¸é…ç½®
    image_width = None
    image_height = None
    if style_config:
        try:
            image_width = Inches(style_config.get('image_width', 4.0))
            image_height = Inches(style_config.get('image_height', 3.0))
        except:
            logger.warning("Failed to get image dimensions from style config")

    # æ·»åŠ æ ‡é¢˜
    title = doc.add_heading(template.name, 0)
    title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER

    # æ·»åŠ ç”Ÿæˆæ—¶é—´
    info_para = doc.add_paragraph()
    info_para.add_run(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    info_para.add_run(f"æ¨¡æ¿: {template.name}")
    info_para.runs[0].font.size = Pt(10)
    info_para.runs[0].font.color.rgb = None

    # æ·»åŠ åˆ†éš”çº¿
    doc.add_paragraph("_" * 80)

    # éå†æ¨¡æ¿çš„ç« èŠ‚ç»“æ„
    def add_section(section, level=1):
        """é€’å½’æ·»åŠ ç« èŠ‚åŠå…¶å†…å®¹"""

        # è·å–ç”Ÿæˆçš„å†…å®¹
        content = generated_content.get(section.id, '')

        # å¦‚æœæœ‰å†…å®¹ï¼Œæ·»åŠ åˆ°æ–‡æ¡£
        if content and content.strip():
            # æ·»åŠ ç« èŠ‚æ ‡é¢˜
            heading_level = min(level, 9)  # Wordæœ€å¤šæ”¯æŒ9çº§æ ‡é¢˜
            doc.add_heading(section.title, heading_level)

            # æ·»åŠ å†…å®¹
            # âœ… ä¿®å¤ï¼šæ·»åŠ æ®µè½æ ·å¼è®¾ç½®ï¼ŒåŒ…æ‹¬é¦–è¡Œç¼©è¿›
            content_para = doc.add_paragraph(content)
            from docx.oxml.ns import qn
            content_para.paragraph_format.line_spacing = 1.5
            content_para.paragraph_format.first_line_indent = Pt(21.0)
            # Set font properties
            for run in content_para.runs:
                run.font.name = 'å®‹ä½“'
                run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
                run.font.size = Pt(12)

            # æ’å…¥åŒ¹é…åˆ°è¯¥ç« èŠ‚çš„å›¾ç‰‡
            section_images = [img for img in image_insertions if img['section_id'] == section.id]
            for img_data in section_images:
                img_para = doc.add_paragraph()
                img_para.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                img_para.paragraph_format.space_after = Pt(12)
                img_para.paragraph_format.space_before = Pt(12)

                try:
                    img_run = img_para.add_run()
                    img_run.add_picture(
                        img_data['image_path'],
                        width=image_width,
                        height=image_height
                    )
                    logger.info(f"  âœ“ Inserted image in section: {section.title}")
                except Exception as e:
                    logger.warning(f"  âœ— Failed to insert image: {e}")
                    img_para.add_run("[å›¾ç‰‡åŠ è½½å¤±è´¥ / Image load failed]")

        # é€’å½’æ·»åŠ å­ç« èŠ‚
        for subsection in section.subsections:
            add_section(subsection, level=level + 1)

    # ä»é¡¶çº§ç« èŠ‚å¼€å§‹
    for section in template.sections:
        if not section.is_optional or generated_content.get(section.id):
            add_section(section)

    # ä¿å­˜æ–‡æ¡£
    doc.save(output_path)
    logger.info(f"æ–‡æ¡£æ„å»ºå®Œæˆ")
